import torch
from torch import nn
import math
from timm.models.vision_transformer import Attention
from lib.models.layers.adapter_upgtaded3 import ECAAttention
from lib.utils.token_utils import token2patch,patch2token

from lib.models.layers.shaf import Mlp

class basic_conv(nn.Module):
    def __init__(self,channels,inter_channels):
        super(basic_conv,self).__init__()
        self.local_att = nn.Sequential(
            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(inter_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self,x):
        x = self.local_att(x)
        return x

class SpectralGatingNetwork(nn.Module):
    def __init__(self, dim, h=20, w=20, SC=768, drop=0.):
        super().__init__()
        self.norm1 = nn.BatchNorm2d(dim)
        self.norm2 = nn.BatchNorm2d(dim)
        # Initialize complex weights
        self.complex_weight = nn.Parameter(torch.randn(h, w // 2 + 1, dim, 2, dtype=torch.float32) * 0.02)
        # Initialize 1x1 convolution and GELU activation
        self.conv1x1_real = nn.Conv2d(dim, dim, kernel_size=1, stride=1, padding=0)
        self.conv1x1_imag = nn.Conv2d(dim, dim, kernel_size=1, stride=1, padding=0)
        self.act = nn.ReLU()


    def forward(self, x):
        x = x.permute(0,3,2,1)
        B, a, b, C = x.shape  # ([2, 16, 16, 8])
        # if spatial_size is None:
        #     a = b = int(math.sqrt(n))
        # else:
        #     a, b = spatial_size
        # x = x.view(B, a, b, C)
        x = x.to(torch.float32)
        # print("ggg:",x.shape)
        # Apply FFT
        x_fft = torch.fft.rfft2(x, dim=(1, 2), norm='ortho')

        # Apply 1x1 convolution and GELU activation
        x_fft_real = x_fft.real.permute(0, 3, 1, 2)
        x_fft_imag = x_fft.imag.permute(0, 3, 1, 2)

        # Apply 1x1 convolution to real and imaginary parts separately
        x_fft_real = self.conv1x1_real(x_fft_real)
        x_fft_imag = self.conv1x1_imag(x_fft_imag)
        x_fft_real = self.act(self.norm1(x_fft_real))
        x_fft_imag = self.act(self.norm2(x_fft_imag))
        x_fft = torch.complex(x_fft_real, x_fft_imag).permute(0, 2, 3, 1)

        # Apply spectral gating
        weight = torch.view_as_complex(self.complex_weight)
        x_fft = x_fft * weight
        x = torch.fft.irfft2(x_fft, s=(a, b), dim=(1, 2), norm='ortho')

        return x.permute(0,3,2,1)

class Attention_Module(nn.Module):
    def __init__(self, dim, norm_layer=nn.LayerNorm):
        super().__init__()
        self.linear = nn.Linear(dim, 8)
        self.act1 = nn.ReLU(inplace=True)
        self.cross_attn = Attention(8, num_heads=8)
        self.end_proj = nn.Linear(8, dim)
        self.norm1 = norm_layer(dim)

    def forward(self, x1):
        # y1, u1 = self.act1(self.linear(x1))
        # y2, u2 = self.act2(self.linear(x2))
        # v1, v2 = self.cross_attn(u1, u2)
        y = self.act1(self.linear(x1))
        v = self.cross_attn(y)

        y1 = y + v

        out_x1 = self.norm1(x1 + self.end_proj(y1))
        return out_x1

class SGBlock(nn.Module):
    def __init__(self, dim = 768, drop=0.):
        super().__init__()
        hidden_dim = 8
        self.adapter_down = nn.Linear(dim, hidden_dim)
        self.basic1 = basic_conv(hidden_dim, hidden_dim)
        self.basic2 = basic_conv(hidden_dim, hidden_dim)
        self.stb_x = SpectralGatingNetwork(hidden_dim, 16, 16)
        self.stb_z = SpectralGatingNetwork(hidden_dim, 8, 8)
        self.conv1x1 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1, stride=1, padding=0)
        self.conv1x1_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1, stride=1, padding=0)
        self.conv3x3 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1)
        self.conv3x3_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1)
        self.norm = nn.BatchNorm2d(hidden_dim)
        self.act = nn.ReLU(inplace=True)
        self.sum = Attention_Module(768)
        self.mlp2 = Mlp(768)
        self.norm2 = nn.LayerNorm(768)
        self.adapter_up = nn.Linear(hidden_dim, dim)

        nn.init.zeros_(self.adapter_down.weight)
        nn.init.zeros_(self.adapter_down.bias)
        nn.init.zeros_(self.adapter_up.weight)
        nn.init.zeros_(self.adapter_up.bias)

    def forward(self, x):
        raw = x
        x0 = self.sum(raw)
        x0 = self.mlp2(self.norm2(x0))

        x = self.adapter_down(x)
        z = x[:,:64,:]
        x = x[:,64:,:]

        z = token2patch(z)
        x = token2patch(x)

        x1 = self.basic1(x)
        res_x1 = x1  # ([2, 8, 16, 16])
        x1 = self.stb_x(x1)  # ([2, 16, 16, 8])
        xo = x1 + res_x1
        xo = self.conv1x1(xo)
        xo = self.norm(xo)
        xo = patch2token((xo))
        xo = self.act(xo)
        x2 = x
        x2 = self.conv3x3(x2)
        xo = token2patch(xo) + x2
        xo = self.norm(xo)
        xo = patch2token((xo))
        xo = self.act(xo)


        z1 = self.basic2(z)
        res_z1 = z1  # ([2, 8, 16, 16])
        z1 = self.stb_z(z1)  # ([2, 16, 16, 8])
        zo = z1 + res_z1
        zo = self.conv1x1_2(zo)
        zo = self.norm(zo)
        zo = patch2token((zo))
        zo = self.act(zo)
        z2 = z
        z2 = self.conv3x3_2(z2)
        zo = token2patch(zo) + z2
        zo = self.norm(zo)
        zo = patch2token((zo))
        zo = self.act(zo)

        xo_f = torch.cat((zo,xo),dim=1)
        xo_f = self.adapter_up(xo_f)
        xo_f = xo_f + x0

        return xo_f


# x = torch.ones(2,320,768)
# m = SGBlock(768)
# o = m(x)
# print(o.shape)